
梯度下降算法
    输出层：Errj = Oj(1-Oj)(Tj-Oj)  #Oj是预测值
    隐藏层：Errj = Oj(1-Oj)Sum(Errk * Wjk)
平均灰度算法 Average Darkness     22.25%准确率
backgropagation算法

示例：
1(1)
        4
2(0)        6(1)
        5
3(1)

x1  x2  x3  w14     w15     w24     w25     w34     w35     w46     w56     b4      b5      b6
1   0   1   0.2     -0.3    0.4     0.1     -0.5    0.2     -0.3    -0.2    -0.4    0.2     0.1

z:
4       0.2+0-0.5 -0.4 = -0.7                       1/(1+exp(0.7)) = 0.332
5       -0.3+0+0.2 +0.2 = 0.1                       1/(1+exp(-0.1)) = 0.525
6       (-0.3)(0.332)+(-0.2)(0.525) +0.1 = -0.105   1/(1+exp(0.105)) = 0.474

Err:
6       (0.474)(1-0.474)(1-0.474) = 0.1311
5       (0.525)(1-0.525)(0.1311)(-0.2) = -0.0065
4       (0.332)(1-0.332)(0.1311)(-0.3) = -0.0087

Weight new value:
w46     -0.3+(0.9)(0.1311)(0.332) = -0.261
w56     -0.2+(0.9)(0.1311)(0.525) = -0.138
w14     0.2+(0.9)(-0.0087)(1) = 0.192
w15     -0.3+(0.9)(-0.0065)(1) = -0.306
w24     0.4+(0.9)(-0.0087)(0) = 0.4
w25     0.1+(0.9)(-0.0065)(0) = 0.1
w34     -0.5+(0.9)(-0.0087)(1) = -0.508
w35     0.2+(0.9)(-0.0065)(1) = 0.194
b6      0.1+(0.9)(0.1311) = 0.218
b5      0.2+(0.9)(-0.0065) = 0.194
b4      -0.4+(0.9)(-0.0087) = -0.408

cross-entropy函数，改善学习效果
    C = -1/n * sum(y*log(a) + (1-y)*log(1-a))
Softmax
Regularization
Dropout
正态分布: 均值=0，标准差=1/sqrt(n)
